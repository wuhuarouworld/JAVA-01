一、JVM

1、JVM命令行工具
1.jps 显示java进程的pid

2.常用的三个命令行工具 jstack jmap jstat

1) jstat 
常用命令 
jstat -gc pid 1000 1000     gc相关的堆内存信息
jstat -gcutil pid 1000 1000 gc相关区域的使用率统计

2) jmap 
常用命令
jmap -heap pid  打印堆内存的配置和使用信息
jmap -histo pid  直方图 看类占用的空间


3）jstack 
常用命令
jstack -l pid
kill -3 让线程把自己的堆栈信息打出来

3. jcmd 

2、JVM图形化工具
1.jconsole 
2.jvisualvm
3.VisualGC Idea内置插件
4.jmc

3、GC
1.为什么要有GC? 内存资源有限
2.引用计数-->循环依赖  内存泄漏 内存溢出 
改进：可达性分析 GC roots
可作为可达的对象：1）当前正在执行的方法里的局部变量和输入参数
                 2）活动线程
                 3）所有类的静态字段
                 4）JNI引用
3.GC分代  
为什么要分代？ 分代假设：大部分新生对象很快无用，存活时间较长的对象，可能存活更长时间
4.GC算法 
复制算法（年轻代）年轻代分了三个区 采用这种算法非常高效
标记清除算法  会产生内存碎片
标记清除整理算法（老年代）

5.GC分类
1）串行GC 
年轻代 标记复制算法  老年代 标记清除整理算法
单线程  适合几百兆堆内存的JVM 单核cpu
2）并行GC
年轻代 标记复制算法  老年代 标记清除整理算法  触发STW事件
GC线程数默认为cpu核数
适用于多核服务器 吞吐量优先  
3）CMS（并发）
年轻代 并行的标记复制算法  老年代 并发的标记清除算法
目标：不对老年代垃圾收集时产生过长时间的卡顿 低延迟
不对老年代进行整理 使用空闲列表来管理内存空间的回收（加了中间层）
使用的并发线程数为cpu核数的1/4
六个阶段
1.初始标记 STW 根对象直接引用的对象 被年轻代中所有存活对象所引用的对象
2.并发标记 遍历老年代 标记所有的存活对象
3.并发预处理 卡片标记 在并发标记过程中引用关系发生了变化
4.最终标记 STW 完成老年代所有存活对象的标记
5.并发清除 删除不再使用的对象 回收占用的内存空间
6.并发重置 重置CMS算法相关的内部数据 为下一次GC循环做准备
4）G1
目标：将STW停顿的时间和分布变为可预期且可配置 自适应
划分为多个Region（通常2048个）堆不再分为年轻代和老年代 逻辑上所有的Eden和survivor区合起来就是年轻代 所有old区合起来就是老年代
增量处理： 每次只处理一部分内存块 每次GC暂停会收集所有年轻代的内存块以及部分的老年代的内存块
创新：并发阶段估算每个小堆块存活对象的总数 垃圾最多的小块会被优先收集
5）ZGC
GC最大停顿时间不超过10ms
JDK15后支持win和mac
6）ShennandoahGC 
7）Java8中默认使用的GC是Parallel GC
8）JDK5--8默认使用的是并行GC，JDK9--15默认使用的是G1

6.常见GC组合
Serial + Serial Old 单线程低延迟垃圾回收机制
ParNew + CMS 多线程低延迟垃圾回收机制
Parallel Scavenge + Parallel Scavenge Old 多线程高吞吐量来及回收机制

7.GC选择
吞吐优先 Parallel GC
低延迟 CMS GC
系统内存堆较大 希望整体平均GC时间可控 G1 GC

8.GC算法和实现的演进路线
1）串行-->并行
2）并行-->并发
3）CMS-->G1
4) G1-->ZGC

二、NIO 模型与 Netty 入门

服务器通信原理

Socket通信模型

服务器通信过程分析
用户空间 内核空间 socket
数据来回复制 

通信模型
同步 异步 是通信模式
阻塞 非阻塞 是线程处理模式

阻塞IO   餐馆排队等吃饭
非阻塞IO 餐馆拿号，每隔一段时间回来看下有没轮到
多路复用IO 餐馆拿好几个号 每隔一段时间看下这几号哪个轮到
信号驱动IO 餐馆拿号，等轮到吃饭了，服务员给你发短信
异步非阻塞IO 餐馆拿号，餐馆直接做好饭叫你吃

Java直接用操作系统的线程 裸线程


BIO NIO AIO 


高性能：
1.高并发用户(Concurrent Users) 同一个时间点有大量的用户访问
2.高吞吐(Throughout) QPS/TPS
3.低延迟(Latency) 偏金融交易的系统重视 P50/P90/P99
4.容量

系统的请求响应时间（RRT） 从调用方的角度 发送请求到收到响应
延迟(Latency)  讲的是进入系统到离开系统 （针对系统内部）
RRT = Latency + 两次网络传输的时间


延迟和吞吐量关系
一般来说，延迟越低 吞吐量越高 但不绝对 
延迟高的系统吞吐量也可能高
例子：水库 望京 大兴

高性能负面：
1.复杂度高
2.建设成本高
3.故障或者bug导致的破坏性大

系统80%的问题出现在系统变更，上线，发布升级，迁移等对系统的变动中
混沌工程 做稳定性 高性能带来的弊端



Netty实现NIO
网络应用开发框架
1.异步
2.事件驱动(多路复用的IO模型)
3.基于NIO

同步和异步可理解为用户态和内核态处理的区别

IO是操作系统层面的东西，由操作系统提供

IO  网络IO/磁盘IO

事件处理机制---> Reactor模型

Reactor模型
事件驱动 多个并发输入源 一个Service Handler  多个EventHandlers处理业务

1.Reactor单线程模型  
2.Reactor多线程模型
3.Reactor主从模型

Netty中EventLoopGroup就是模型中的Reactor
Channel是跟IO相关处理的一个抽象的概念，读写数据的管道

所有的业务系统都可以看作是管道+过滤器的模式

Netty内部
EventLoop可看作一个工作单元，类似JVM，包含一个Thread
Channel绑定到EventLoop上后，有数据进行读写，EventLoop对它进行处理，自定义的Handler等


关键对象 Bootstrap: 启动线程，开启 socket 
EventLoopGroup 
EventLoop 
SocketChannel: 连接 
ChannelInitializer: 初始化 
ChannelPipeline: 处理器链 绑很多的处理器 
ChannelHandler: 处理器

Inbond 入站
OutBond  出站

粘包和拆包的问题

网络拥堵与 Nagle 算法优化
优化条件： - 缓冲区满  - 达到超时
MTU = 1500 Byte  MSS = MTU - 20(IP) - 20(TCP) = 1460 Byte 

三次握手 四次挥手
四次挥手断开连接的最后一步等待两个MSL，是为了防止最后发的ACK可能会丢失，立马断开可能会出异常

网关
职能：请求接入 业务聚合 中介策略 统一管理

流量网关 nginx OpenResty Kong  性能好
业务网关 Spring Cloud Gateway   soul  Zuul2  对服务的增强 拓展性好 适合业务网关



三、Java并发编程

为什么有多线程？
本质：摩尔定律的失效  多核+分布式的时代

多核cpu意味着操作系统同时有更多的并行计算资源可以使用

进程和线程
进程是操作系统分配资源的基本单位 程序
线程是操作系统调度的基本单元

Java线程的创建过程
Java层面 JVM层面 OS层面

Java层面的Thread是一个对象 通过JVM层面创建，管理，使用，终结操作系统对应的线程


每一个new出来的Thread，都对应操作系统的真实线程  裸线程

main方法是程序入口，主线程main
守护线程

start（）--> 创建操作系统的线程 启动新的线程并执行Runnable中的run方法
直接调用run（）方法  在当前线程执行run方法

线程池：任务执行器
Executor 顶层接口
ExecutorService 接口API
ThreadFactory 线程工厂
Executors 工具类

Executor 执行者 
execute方法

ExecutorService 
execute方法 没有返回值 捕捉不到异常
submit方法 有返回值 封装在Future中 方法抛异常可以在主线程中被捕捉到
shutdown()：停止接收新任务，原来的任务继续执行
shutdownNow()：停止接收新任务，原来的任务停止执行
awaitTermination(long timeOut, TimeUnit unit)：当前线程阻塞


ThreadFactory
newThread方法 创建新线程

自定义线程池
ThreadPoolExecutor

1. 判断 corePoolSize 【创建】
2. 加入 workQueue
3. 判断 maximumPoolSize 【创建】
4. 执行拒绝策略处理器

DK核心库的包

JUC 

锁  原子类  线程池 工具类  集合类

锁机制类 Locks：Lock Condition ReentrantLock ReadWriteLock LockSupport
原子操作类 Atomic：AtomicInteger AtomicLong LongAdder
线程池相关类 Executor：Future Callable Executor ExecutorService
信号组工具类 Tools：CountDownLatch CyclicBarrier Semaphore
并发集合类 Collections：CopyOnWriteArrayList ConcurrentMap

集合类
List:ArrayList LinkedList Vector Stack
Set: LinkedSet HashSet TreeSet
Queue Deque LinkedList

Map: HashMap LinkedHashMap TreeMap 
Dictionary HashTable Properties

四、框架

Spring

提供了一种方法论  项目的拆分 分工 协作  进度跟踪
引入Spring 意味着引入了一种研发协作模式
复杂的业务系统开发变的简单

Pivotal公司

snapshot  RC(release 候选者)  release  GA(没什么大的bug)

框架：没有业务功能 为业务服务
中间件：要求可独立部署


Spring 管理控制Bean

Spring framework 6大模块
1.Core: Bean/Context/AOP
2.Testing: Mock/TestContext
3.DataAccess:Tx/JDBC/ORM
4.Spring MVC/WebFlux:web
5. Integration: remoting/JMS/WS
6. Languages: Kotlin/Groovy  

孵化：Spring fu   Spring roo

Spring 早期版本的核心功能，管理对象生命周期与对象装配
为了实现管理和装配，加一个中间层代理（字节码增强）来实现所有对象的托管

循环依赖 属性依赖（可解决） 构造器依赖（解决不了）

AOP-面向切面编程

一个对象的代理有哪些种类？用在什么场景？

接口类型  默认使用 JdkProxy com.sun.proxy.$Proxy
		 proxyTargetClass  EnhancerBySpringCGLIB	

非接口类型 默认使用 CGlib EnhancerBySpringCGLIB


OOP --> 反射(reflect) --> 字节码增强(emit)

运行的时候直接凭空创造新的子类继承老的类

AOP --> 字节码操作集合 CGLIB ASM AspectJ  Java Proxy  Javassist Instrumentation

字节码增强新工具：ByteBuddy  

Instrumentation：对应 Java Agent   在JVM把字节码加载到内存前 直接改类 名字还是这个类 里面内容和原先不同


Spring Bean生命周期

设计如此复杂的原因：
1.管理各种复杂的bean对象 2.为了更加灵活

BeanFactory ---> ApplicationContext

构造函数(1.实例化)--> 依赖注入(2.属性赋值)  
--> BeanNameAware --> BeanFactoryAware --> 
ApplicationContextAware --> BeanPostProcessor前置方法 --> 
InitializingBean --> 自定义init方法 --> BeanPostProcessor后置方法(3.初始化)
--> 使用 --> DisposableBean --> 自定义destroy方法(4.销毁)

可对照Classloader加载

Bean的加载过程
1）创建对象
2）属性赋值
3）初始化  
4）注销接口注册

初始化：
1）检查 Aware 装配
2）前置处理、After 处理
3）调用 init method
4）后置处理

自动化 XML配置工具：
XmlBeans -> Spring-xbean
2个原理：
1、根据 Bean 的字段结构，自动生成 XSD
2、根据 Bean 的字段结构，配置 XML 文件    (使用反射的技术)


Spring Bean 配置方式演化

XML @Autowire  1.0/2.0 XML配置/注解注入

@Service       2.5     半自动注解配置

@Bean @Configuration 3.0  Java Config配置

@Condition @AutoConfigureX 4.0/SpringBoot 全自动注解配置

Spring Boot 出发点

一切都是为了简化
开发，配置，运行变简单

整合

如何变简单：约定大于配置

脚手架

Spring Boot 两大核心原理
1、自动化配置：简化配置核心
基于 Configuration，EnableXX，Condition
2、spring-boot-starter：脚手架核心
整合各种第三方类库，协同工具

五、数据库

数据库设计范式
1NF：消除重复数据，即每一列都是不可再分的基本数据项；
每个列都是原子的。
2NF：消除部分依赖，表中没有列只与主键的部分相关，即每一行都被主键唯一标识；
每个列都有主键。
3NF：消除传递依赖，消除表中列不依赖主键，而是依赖表中的非主键列的情况，即没
有列是与主键不相关的。从表只引用主表的主键，即表中每列都和主键相关。
BCNF：Boyce-Codd Normal Form（巴斯-科德范式）
3NF的基础上消除主属性对于码的部分与传递函数依赖。

MySQL 存储
独占模式
1）、日志组文件：ib_logfile0和ib_logfile1，默认均为5M
2）、表结构文件：*.frm
3）、独占表空间文件：*.ibd
4）、字符集和排序规则文件：db.opt
5）、binlog 二进制日志文件：记录主数据库服务器的 DDL 和 DML 操作
6）、二进制日志索引文件：master-bin.index
共享模式 innodb_file_per_table=OFF  数据都在 ibdata1

MySQL 简化执行流程
SQL --> 查询缓存 --> 解析器 --> 预处理器 --> 查询优化器 --> 执行计划
--> 查询执行引擎(API接口调用) --> 存储引擎 --> 数据

MySQL 详细执行流程(见ppt)

Server层
1.更新记录ID=2这行 2.连接器(管理连接 权限验证) 3.分析器(词法/语法分析)
3.查询缓存(命中返回结果) 4.优化器(执行计划生成 索引选择) 5.执行器
引擎层
6.写undo log(用于回滚/崩溃恢复/MVCC) 
7.记录所在目标页是否存在于内存中
存在：8.找到数据，判断是否冲突，更新内存(唯一索引) 
     8.找到数据，更新内存(唯一索引)
不存在： 8.将数据页从磁盘读入内存 判断是否冲突 更新(唯一索引)
        8.在change buffer更新记录 change buffer会异步将更新同步到磁盘(普通索引)
    通过change buffer降低磁盘IO次数

9.写入redo log(用于事务崩溃恢复)
10.写binlog(用于备份/主从同步)
11.提交事务
12.刷redo log盘 处于commit-prepare阶段
13.刷binlog 处于commit-commit阶段
两阶段提交：为了让binlog和redolog两个日志之间的逻辑一致


MySQL 执行引擎和状态
mysiam 支持索引 表锁 支持数据压缩 (内部存储了count *，可立即返回) 适用对事务和一致性要求不高的场景
innodb 支持事务 支持索引 行锁 支持外键
memory 支持索引 表锁
archive 行锁 支持数据压缩

MySQL 对 SQL 执行顺序
1.from 2.on 3.join
4.whrere 5.group by  6.having+聚合函数 7.select 
8.order by 9.limit

MySQL 索引原理
数据是按页来分块的 当一个数据被用到时，其附近的数据也通常会马上被使用
InnoDB 使用 B+ 树实现聚集索引 固定大小的页来存储 数据表中的数据都是存储在页中

为什么一般单表数据不超过2000万？
1.假设一行数据是1k，一个页通常为16k 可以存放16行数据(16条记录)
2.Innodb存储引擎最小存储单元是页 页可以用于存放数据，键值+指针
b+树中叶子节点存放数据，非叶子节点存放键值+指针
3.索引组织表通过非叶子节点的二分查找法及指针确定数据在哪个页，进而在数据页中查找到需要的数据。为了和磁盘io交互次数2--3次就能找到记录，假设树的层数不超过3层
4.假设主键ID为bigint，长度为8字节，指针大小在innodb中为6字节，则一页中可以存放
16384/14=1170 即1170个指针(key)
5.高度为3的B+树，可以存放1170*1170*16(行) = 21902400(两千万)条记录

场景：一行数据太长，需要拆表

MySQL 配置优化

show命令 select命令
查看参数配置
- show variables like xxx
my.cnf 文件

MySQL 事务

事务可靠性模型 ACID
Atomicity: 原子性  一次事务中的操作要么全部成功, 要么全部失败
Consistency：一致性 跨表、跨行、跨事务, 数据库始终保持一致状态
Isolation: 隔离性  可见性, 保护事务不会互相干扰, 包含4种隔离级别
Durability: 持久性 事务提交成功后,不会丢数据。如电源故障, 系统崩溃。

表级锁
意向锁: 表明事务稍后要进行哪种类型的锁定
•共享意向锁(IS): 打算在某些行上设置共享锁
•排他意向锁(IX): 打算对某些行设置排他锁
•Insert 意向锁: Insert 操作设置的间隙锁
•共享锁(S)
•排他锁(X)

上锁前需要先上意向锁
X锁和其他所有类型的锁冲突
IX和X锁，S锁冲突
S锁和X锁，IX锁冲突
IS锁和X锁冲突

行级锁(InnoDB)
记录锁(Record): 始终锁定索引记录，注意隐藏的聚簇索引; 
•间隙锁(Gap): 锁住一个范围
•临键锁(Next-Key): 记录锁+间隙锁的组合; 可“锁定”表中不存在记录
•谓词锁(Predicat): 空间索引

死锁: 
-阻塞与互相等待
-增删改、锁定读
-死锁检测与自动回滚
-锁粒度与程序设计

MySQL 隔离级别
可设置全局的默认隔离级别以及单独设置会话级别
事务隔离是数据库的基础特征
并发性  可靠性  一致性  复性

读未提交 READ UNCOMMITTED
很少使用 不能保证一致性 会导致数据脏读：使用到从未被确认的数(早期版本 回滚)
锁: •以非锁定方式执行   •脏读 幻读 不可重复读

读已提交 READ COMMITTED
•不可重复读: 不加锁的情况下, 其他事务 UPDATE 或 DELETE 会对查询结果有影响
•幻读(Phantom): 加锁后, 不锁定间隙, 其他事务可以 INSERT
锁: 
•锁定索引记录, 而不锁定记录之间的间隙
•可能的问题: 幻读、不可重复读

可重复读  REPEATABLE READ
•InnoDB 的默认隔离级别
•使用事务第一次读取时创建的快照
•多版本技术(MVCC)
•可能的问题: InnoDB 不能保证没有幻读, 需要加锁

怎么解决? 
提高隔离级别、使用间隙锁或临键锁

串行化: SERIALIZABLE
最严格的级别，事务串行执行，资源消耗最大

undo log:撤销日志
•保证事务的原子性
•用处: 事务回滚, 一致性读、崩溃恢复
•记录事务回滚时所需的撤消操作
•一条 INSERT 语句，对应一条 DELETE 的 undo log
•每个 UPDATE 语句，对应一条相反 UPDATE 的 undo log
保存位置: 
•system tablespace (MySQL 5.7默认) 
•undo tablespaces (MySQL 8.0默认)

redo log: 重做日志
•确保事务的持久性，防止事务提交后数据未刷新到磁盘就掉电或崩溃。
•事务执行过程中写入 redo log,记录事务对数据页做了哪些修改。
•提升性能: WAL(Write-Ahead Logging) 技术, 先写日志, 再写磁盘。
•日志文件: ib_logfile0, ib_logfile1
•日志缓冲: innodb_log_buffer_size
•强刷: fsync()

MVCC: 多版本并发控制
•使 InnoDB 支持一致性读: READ COMMITTED 和 REPEATABLE READ
•让查询不被阻塞、无需等待被其他事务持有的锁，这种技术手段可以增加并发性能。
•InnoDB 保留被修改行的旧版本。
•查询正在被其他事务更新的数据时，会读取更新之前的版本。
•每行数据都存在一个版本号, 每次更新时都更新该版本
聚簇索引的更新 = 替换更新
二级索引的更新 = 删除+新建

MVCC 实现机制
•隐藏列
•事务链表， 保存还未提交的事务，事务提交则会从链表中摘除
•回滚段: 通过 undo log 动态构建旧版本数据

SQL优化
数据类型选择要合适
存储引擎一般用InnoDB
简单的sql可能带来大的问题，where条件中注意数据类型，避免类型转换
定位问题的方法：慢查询日志 看应用和运维监控
增加索引：alter table table_name add index index_name(column_list);
索引的类型：Hash B-Tree/B+Tree
B树和B+树的区别：
1.B树非叶子节点同时存储索引和数据，会导致一层上索引数较少，树的层数增多;B+树非叶子节点只存索引
2.B+树叶子节点上存储的数据页之间是链表的结构连接，适合范围查询;B树没有
为什么主键要单调递增？为了防止页分裂
为什么主键长度不能过大？主键长度过大，一层上能存放key数目会减少，导致树层数增加
哪个快？
select * from t_user_info where f_id = XXX  //f_id:primary key
select * from t_user_info where f_user_name = 'XXX' //f_user_name:index
第一个快。第一个是聚集索引，第二个是二级索引，需要回表操作，通过二级索引找到主键key，再回表通过key找到数据
字段选择性-最左原则
某个字段其值的重复程度，称为该字段的选择性
F=DISTINCT(col)/count(*) 越接近1，字段的选择性越好
修改表结构的危害：1.索引重建 2.锁表 3.抢占资源 4.主从延时
数据量：1.业务初期考虑不周，字段类型使用不合理，需要变更数据类型； 2.随着业务的发展，需要添加新的字段(使用拓展表)
3.在无索引字段增加新的业务查询，需要增加索引

总结：
1.写入优化
大批量写入的优化
PreparedStatement 减少 SQL 解析
Multiple Values/Add Batch 减少交互
Load Data，直接导入
索引和约束问题
2.数据更新
数据的范围更新
注意 GAP Lock 的问题 导致锁范围扩大
3.模糊查询
Like 的问题  
前缀匹配  %张三%不走索引
否则不走索引
全文检索，
solr/ES
4.连接查询
连接查询优化
驱动表的选择问题
避免笛卡尔积
5.索引失效
索引失效的情况汇总
NULL，not，not in，函数等
减少使用 or，可以用 union（注意 union all 的区别），以及前面提到的like
大数据量下，放弃所有条件组合都走索引的幻想，出门左拐“全文检索”
必要时可以使用 force index 来强制查询走某个索引
6.查询 SQL 到底怎么设计？
查询数据量和查询次数的平衡
避免不必须的大量重复数据传输(如查询出数据到Java代码上计算出size)
避免使用临时文件排序或临时表
分析类需求，可以用汇总表


怎么实现主键 ID
- 自增 mysql内部维护一个内存变量，变量一直递增，mysql重启后会重新读取最大的id值，然后加1给下一条数据
- sequence(oracle DB2)
- 模拟 seq
建立一个表，里面的变量每次去取后加1，可以设置步长，类似批发，但可能导致主键递增的值不连续   
- UUID 性能较差
- 时间戳/随机数
- snowflake 分布式下的常用方法

分布式事务
分布式条件下，多个节点操作的整体事务一致性
微服务场景下，业务 A 和业务 B 关联，事务 A 成功，事务 B 失败，由于跨系统，
就会导致不被感知。此时从整体来看，数据是不一致的

两个原子性的操作合起来不是原子性
例：两张表 商品表和商品详情表  都放在一个数据库里 分别往两张表里插入数据 在一个事务里是原子性的
两张表放在两个数据库 第一张表插入数据 成功 第二张表插入数据可能成功，也可能失败
若失败，能查到商品的id，但查不到该商品的详情，数据的一致性被破坏

分布式系统会带来数据一致性问题 从而产生分布式事务

如何实现分布式下的一致性：
1、理想状态：直接像单机数据库事务一样，多个数据库自动通过某种协调机制，实现了
跨数据库节点的一致性。
使用场景：要求严格的一致性，比如金融交易类业务。
2、一般情况：可以容忍一段时间的数据不一致，最终通过超时终止，调度补偿，等等方
式，实现数据的最终状态一致性。
使用场景：准实时或非实时的处理，比如 T+1 的各类操作，或者电商类操作。

强一致：XA
弱一致：1.不用事务 业务侧补偿冲正  2.柔性事务 使用一套事务框架保证最终一致的事务


XA 分布式事务
XA 整体设计思路可以概括为，如何在现有事务模型上微调扩展，实现分布式事务

XA 分布式事务协议
应用程序(Application Program ，简称AP)：用于定义事务边界(即定义事务的开始和
结束)，并且在事务边界内对资源进行操作。
资源管理器(Resource Manager，简称RM)：如数据库、文件系统等，并提供访问资
源的方式
事务管理器(Transaction Manager ，简称TM)：负责分配事务唯一标识，监控事务的执行
进度，并负责事务的提交、回滚等。

xa_start ：负责开启或者恢复一个事务分支
xa_end： 负责取消当前线程与事务分支的关联
xa_prepare：询问 RM 是否准备好提交事务分支
xa_commit：通知 RM 提交事务分支
xa_rollback： 通知 RM 回滚事务分支
xa_recover : 需要恢复的 XA 事务

本地mysql支持xa事务，用同一个全局id标识不同的本地事务，从而达到强一致性
MySQL 从5.0.3开始支持 InnoDB 引擎的 XA 分布式事务

MySQL 属于资源管理器(RM)。分布式事务中存在多个 RM，由事务管理器 TM 来统一进行协调

xa事务和非xa事务(本地事务)是互斥的 
例如：执行xa start命令开启xa事务后，本地事务不会被启动，直到xa事务已经提交或者回滚为止。相反，如果已经使用start transaction启动一个本地事务，则xa语句不能被使用，知道本地事务被提交或者回滚为止

1、业务 SQL 执行过程，某个 RM 崩溃怎么处理？ 
全部回滚
2、全部 prepare 后，某个 RM 崩溃怎么处理？
TM若commit，崩溃的RM重启后commit；TM若rollback，则全部回滚
3、commit 时，某个 RM 崩溃怎么办？
RM重启后commit

主流支持 XA 的框架，比较推荐 Atomikos 和 narayana

xa默认不会改变隔离级别

xa协议存在的问题
1.同步阻塞问题 一般情况下，不需要调高隔离级别 
在xa下，本地事务都是并行执行的，commit到数据库的时间是不一致的
2.单点故障 成熟的xa框架需要考虑TM的高可用性
若TM发生故障，RM会一直阻塞下去。尤其在第二阶段，TM故障，所有RM还处于锁定事务状态，无法继续完成事务操作
3.数据不一致 极端情况下，一定有事务失败的问题 需要监控和人工处理
二阶段提交的阶段二中，当协调者向参与者发送commit请求后，发生局部网络异常或者发送commit的请求过程中协调者发生故障，会导致只有一部分参与者接收到了commit请求，这部分参与者执行了commit操作，而另一部分未接到commit，无法执行事务提交，整个分布式系统就会出现数据不一致的情况

BASE 柔性事务
本地事务 -> XA(2PC) -> BASE
BASE 是基本可用、柔性状态和最终一致性这三个要素的缩写。
• 基本可用（Basically Available）保证分布式事务参与方不一定同时在线。
• 柔性状态（Soft state）则允许系统状态更新有一定的延时，这个延时对客户来说不一定能够
察觉。
• 而最终一致性（Eventually consistent）通常是通过消息传递的方式保证系统的最终一致性。

在 ACID 事务中对隔离性的要求很高，在事务执行过程中，必须将所有的资源锁定。 柔性事务的理念则是通过业务逻辑将互斥锁操作从资源层面上移至业务层面。通过放宽对强一致性要求，来换取系统吞吐量的提升。

BASE 柔性事务常见模式
1、TCC
通过手动补偿处理
2、AT
通过自动补偿处理
3.saga
补偿冲正

TCC
1.try接口 检查并预留必须的业务资源 
2.Confirm接口 真正执行业务逻辑 只使用Try阶段预留的业务资源
3.Cancel接口 释放Try阶段预留的业务资源

例子：
A: 账户9 USD  B:账户12 CHB  
A和B交易1 USD 换 7 CHB 
try阶段：检查账户 分别预留A账户 1USD 和 B账户 7CHB 锁定业务资源
Confirm阶段:执行 锁定的那部分资源
若操作失败 Cancel取消try预留的资源
三个阶段对应三个小事务

TCC 不依赖 RM 对分布式事务的支持，而是通过对业务逻辑的分解来实现分布式事务，
不同于AT的是就是需要自行定义各个阶段的逻辑，对业务有侵入。

SAGA
Saga 模式没有 try 阶段，直接提交事务。

AT 模式就是两阶段提交，自动生成反向 SQL(可看作TCC和Saga的增强)

事务特性
• 原子性（Atomicity）：正常情况下保证。
• 一致性（Consistency），在某个时间点，会出现 A 库和 B 库的数据违反一致性要求的情况，但是最终是
一致的。
• 隔离性（Isolation），在某个时间点，A 事务能够读到B事务部分提交的结果。
• 持久性（Durability），和本地事务一样，只要 commit 则数据被持久。

隔离级别
• 一般情况下都是读已提交（全局锁）、读未提交（无全局锁）。
TCC是读未提交，AT是读已提交


Seata-TCC/AT 柔性事务
分布式事务框架
Seata AT 事务模型包含TM (事务管理器)，RM (资源管理器) 和 TC (事务协调器)
Seata 管理的分布式事务的典型生命周期：
TM 要求 TC 开始一个全新的全局事务。
TC 生成一个代表该全局事务的 XID。
XID 贯穿于微服务的整个调用链。
TM 要求 TC 提交或回滚 XID 对应全局事务。
TC 驱动 XID 对应的全局事务下的所有分支事务完成提交或回滚。

Seata - AT 原理
两阶段提交协议的演变：
一阶段：业务数据和回滚日志记录在同一个本地事
务中提交，释放本地锁和连接资源。
二阶段：
提交异步化，非常快速地完成。
回滚通过一阶段的回滚日志进行反向补偿。

通过全局锁的方式，实现读写隔离。
1、本地锁控制本地操作；
2、全局锁控制全局提交。

高可用读写分离

单机mysql数据库的问题：
1.容量有限，难以扩容
2.读写压力，QPS过大
3.可用性不足，宕机问题

技术演进：
读写压力 --> 多机集群 主从复制
高可用性 --> 故障转移(Failover) MHA/MGR/Orchestrator
容量问题 --> 数据库拆分 分库分表

MySQL 高可用
为什么要高可用？
1.读写分离，提升读的能力
2.故障转移，提供failover能力
加上业务侧连接池的心跳重试，实现断线重连，业务不间断，降低RTO和RPO

主库宕机，从库升为主库，和业务侧重新连接上

高可用意味着更少的不可服务时间，一般用SLA/SLO
99，99.9，99.99，99.999

failover：故障转移 灾难恢复
容灾：冷备，热备
整个集群正常对外提供服务

常见的策略：
1.多个实例不在一个主机/机架上
2.跨机房和可用区部署
3.两地三中心容灾高可用方案

MySQL 高可用0：主从手动切换
如果主节点挂掉，将某个从改成主；
重新配置其他从节点。
修改应用数据源配置。
不足：1.数据可能不一致 2.需要人工干预 3.代码和配置的侵入性

MySQL 高可用1：主从手动切换
用 LVS+Keepalived 实现多个节点的探活+请求路由。
配置 VIP 或 DNS 实现配置不变更。
不足：1.手工处理主从切换 2.大量的配置和脚本定义

MySQL 高可用2：MHA
目前在 MySQL 高可用方面是一个相对成熟的解决方案
是一套优秀的作为 MySQL 高可用性环境下故障切换和主从提升的高可用软件
一般能在30s内实现主从切换。切换时，直接通过 SSH 复制主节点的日志。
不足：1. 需要配置 SSH 信息   2. 至少3台

MySQL 高可用3：MGR * (MySQL Group Replication)
如果主节点挂掉，将自动选择某个从改成主；
无需人工干预，基于组复制，保证数据一致性。基于paxos算法
不足：1. 外部获得状态变更需要读取数据库。 2. 外部需要使用 LVS/VIP 配置。

MGR特点：
1.高一致性 基于paxos算法
2.高容错性 不超过半数的节点宕机，就能继续对外提供服务 内置防脑裂保护机制
3.高拓展性 节点增加和移除自动更新组成员信息 新节点增加后自动从其他节点同步增量数据
4.高灵活性 提供单主和多主模式 多主模式支持多节点写入

适用场景：弹性复制 高可用分片

MySQL 高可用4：MySQL Cluster
MySQL InnoDB Cluster 高可用框架 完整的数据库层高可用解决方案
组成：
1.MySQL Group Replication:提供DB拓展，自动故障转移
2.MySQL Router 中间件 提供应用程序连接目标的故障转移和负载均衡
3.MySQL Shell 新的MySQL客户端 多种接口模式 可设置群组复制及Route 
管理InnoDB Cluster

MySQL 高可用5：Orchestrator
基于 Go 语言开发，实现了中间件本身的高可用
优势：能直接在 UI 界面 拖拽改变主从关系

数据库拆分

单库单表无法满足海量数据
1、无法执行 DDL，比如添加一列，或者增加索引，都会直接影响线上业务，导致长时
间的数据库无响应
2、无法备份，与上面类似，备份会自动先 lock 数据库的所有表，然后导出数据，量
大了就没法执行了
3、影响性能与稳定性，系统越来越慢，随时可能会出现主库延迟高，主从延迟很高，
且不可控，对业务系统有极大的破坏性影响

提升容量-->分库分表，分布式，多个数据库，作为数据分片的集群提供服务
降低单个节点的写压力  提升整个系统的数据容量上限

全部数据  通过 clone 整个系统复制，集群   数据复制  主从结构、备份与高可用
业务分类数据  通过解耦不同功能复制，业务拆分  垂直分库分表  分布式服务化、微服务
任意数据  通过拆分不同数据扩展，数据分片  水平分库分表   分布式结构、任意扩容


数据库垂直拆分
垂直分库分表 --> 分布式服务化 --> 微服务架构

垂直拆分（拆库）：将一个数据库，拆分成多个提供不同业务数据处理能力的数据库
这种方式对业务系统有极大的影响，因为数据结构本身发生了变化，SQL和关联关系也必随之发生了改变

垂直拆分（拆表）：如果单表数据量过大，还可能需要对单表进行拆分
这个对业务系统的影响有时候可能会大到跟新作一个系统差不多。
一般情况下，尽量少用这种办法

垂直拆分的优缺点
优点：
1、单库（单表）变小，便于管理和维护
2、对性能和容量有提升作用
3、改造后，系统和数据复杂度降低
4、可以作为微服务改造的基础

1、库变多，管理变复杂
2、对业务系统有较强的侵入性
3、改造过程复杂，容易出故障
4、拆分到一定程度就无法继续拆分

垂直拆分的一般做法
1、梳理清楚拆分范围和影响范围
2、检查评估和重新影响到的服务
3、准备新的数据库集群复制数据
4、修改系统配置并发布新版上线

一般先拆分系统，再拆分数据库

数据库水平拆分
水平拆分就是直接对数据进行分片，有分库和分表两个具体方式，但是都只是降低单个节点数据量，但不改变数据本身的结构
水平分库分表分为：1.分库 2.分表 3.分库分表
1.分库：数据库里有三张表，拆分后为库1，库2 每个库各有三张表
2.分表：三张表在一个库里，拆分后为六张表
3.分库分表：三张表拆分为两个库，单库里又拆分为六张表 （2 * 2）

分表不能提高单库的I/O性能 
原因在于单库里拆分的表，原先落在该库的查询等操作现在仍然落在该库上
有些 DBA 不建议分表，只建议分库
基于此理论，mycat等数据库中间件只支持分库，不支持分表
可以用分库来模拟分表：一个mysql实例可以创建多个db，把数据拆成多个db，类似分表

水平拆分（按时间分库分表）：很多时候，我们的数据是有时间属性的，所以自然可以按照时间维度来拆分
强制按条件指定分库分表：比如配置好某些用户的数据进入单独的库表，其他数据默认处理
自定义方式分库分表：指定某些条件的数据进入到某些库或表。

一般情况下，如果数据本身的读写压力较大，磁盘 IO已经成为瓶颈，那么分库比分表要好。
分库将数据分散到不同的数据库实例，使用不同的磁盘，从而可以并行提升整个集群的并行数据处理能力。相反的情况下，可以尽量多考虑分表，降低单表的数据量，从而减少单表操作的时间，同时也能在单个数据库上使用并行操作多个表来增加处理能力。

mysql高版本(5.7)里面有partition的概念，相当于内置了分表的功能

分库分表有什么优缺点：
1、解决容量问题
2、比垂直拆分对系统影响小
3、部分提升性能和稳定性
1、集群规模大，管理复杂
2、复杂 SQL 支持问题（业务侵入性、性能）
3、数据迁移问题
4、一致性问题

数据的分类管理
1.最近一周下单但是未支付的订单，被查询和支付的可能性较大，再长时间的订单，我们可
以直接取消掉。
2. 最近 3 个月下单的数据，被在线重复查询和系统统计的可能性最大。
3. 超过 3 个月、3 年以内的数据，查询的可能性非常小，我们可以不提供在线查询。
4. 3 年以上的数据，我们可以直接不提供任何方式的查询。

这样的话，我们就可以采取一定的手段去优化系统：
1. 定义一周内下单但未支付的数据为热数据，同时放到数据库和内存；
2. 定义三个月内的数据为温数据，放到数据库，提供正常的查询操作；
3. 定义3个月到3年的数据，为冷数据，从数据库删除，归档到一些便宜的磁盘，用压缩的
方式（比如 MySQL 的 tokuDB引擎，可以压缩到几十分之一）存储，用户需要邮件或者提
交工单来查询，我们导出后发给用户；
4. 定义 3 年以上的数据为冰数据，备份到磁带之类的介质上，不提供任何查询操作。

4. 框架和中间件
Java 框架层面：
- TDDL
- Apache ShardingSphere-JDBC
中间件层面：
- DRDS（商业闭源）
- Apache ShardingSphere-Proxy
- MyCat/DBLE
- Cobar
- Vitness
- KingShard

Apache ShardingSphere 是一套开源的分布式数据库中间件解决方案组成的生态圈，
它由 JDBC、Proxy 和 Sidecar（规划中）这 3 款相互独立，却又能够混合部署配合使用
的产品组成。 它们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于
如 Java 同构、异构语言、云原生等各种多样化的应用场景。


框架 ShardingSphere-JDBC
直接在业务代码使用。
支持常见的数据库和 JDBC。
Java only。

中间件 ShardingSphere-Proxy
作为中间件，独立部署，对业务端透明。
目前支持 MySQL 和 PostgreSQL。
任何语言平台的系统都可以接入，可以使用 mysql 命令或者 IDE 操作。
对业务系统侵入性小。

数据迁移
迁移是最容易出故障的一个点
- 设计新系统容易，但是我们处理的都是老系统和历史数据
- 怎么能更平滑的迁移旧数据到新的数据库和系统
- 特别是在异构的数据库结构情况下
- 达到数据准确，迁移速度快，减少停机，对业务影响小


数据迁移的方式：全量
- 全量数据导出和导入
1、业务系统停机，
2、数据库迁移，校验一致性，
3、然后业务系统升级，接入新数据库。
直接复制的话，可以 dump 后全量导入
（如果是）异构数据，需要用程序来处理

数据迁移的方式：全量+增量
数据迁移的方式：全量+增量
- 依赖于数据本身的时间戳
1、先同步数据到最近的某个时间戳
2、然后在发布升级时停机维护，
3、再同步最后一段时间（通常是一天）的变化数据。
4、最后升级业务系统，接入新数据库。


数据迁移的方式：binlog+全量+增量
- 通过主库或者从库的 binlog 来解析和重新构造数据，实现复制。
- 一般需要中间件等工具的支持。
可以实现多线程，断点续传，全量历史和增量数据同步。
继而可以做到：
1、实现自定义复杂异构数据结构；
2、实现自动扩容和缩容，比如分库分表到单库单表，单库单表到分库分表，分4个库表
到分64个库表。

迁移工具 ShardingSphere-scaling
• 支持数据全量和增量同步。
• 支持断点续传和多线程数据同步。
• 支持数据库异构复制和动态扩容。
• 具有 UI 界面，可视化配置。



分布式系统的两大基石： RPC MQ

RPC基本原理
RPC：远程过程调用 "像调用本地方法一样调用远程方法"
RPC原理：
核心是代理机制
1.本地代理存根：Stub
2.本地序列化反序列化
3.网络通信
4.远程序列化反序列化
5.远程服务存根：Skeleton
6.调用实际业务服务
7.原路返回服务结果
8.返回给本地调用方
注意处理异常

1.设计
RPC基于接口的远程服务调用
本地应用程序与远程应用程序共享POJO实体类定义，接口定义
另一种选择WSDL/WADL/IDL
远程--->服务提供者 本地--->服务消费者

2.代理
代理可以选择动态代理或者字节码增强

3.序列化
1.语言原生的序列化：RMI，Remoting
2.二进制平台无关：Hessian，avro，kyro，fst等
3.文本,JSON,XML

4.网络传输
-TCP/SSL/TSL
-HTTP/HTTPS

HTTP性能上不如TCP,但是假如我们调用远程的接口，想额外传输几个参数，使用HTTP，可以把这些参数放到请求头里传递到服务器

5.查找实现类
通过接口查找服务端的实现类 Skelton
一般是注册方式：dubbo默认将接口与实现类配置到Spring
本地调用相应的接口时，服务端的存根会找到相应的实现类，执行对应的方法

Dubbo

Apache Dubbo是一款高性能，轻量级的开源Java服务框架

六大核心能力： 面向接口代理的高性能RPC调用，智能负载均衡，服务自动注册和发现，高度可扩展能 力，运行期流量调度，可视化的服务治理与运维。

主要功能：
基础功能：RPC调用
-多协议（序列化 传输 RPC）
-服务注册发现
-配置 元数据管理

框架分层设计，可任意组装和扩展

扩展功能：集群、高可用、管控
- 集群，负载均衡 
- 治理，路由
 - 控制台，管理与监控

 Dubbo技术原理
 整体架构：10层
 框架设计：见ppt

 1.Service层 具体业务实现
 2.Config配置层 对外配置接口 以ServiceConfig，ReferenceConfig为中心 可以直接初始 化配置类，也可以通过 spring 解析配置生成配置类
 3.proxy服务代理层 生成服务的客户端Stub和服务器端Skeleton 以ServiceProxy为中心
 4.registry注册中心层 封装服务地址的注册与发现 以服务URL为中心 拓展接口为RegistryFactory Registry RegistryService
 5.cluster路由层 封装多个提供者的路由和负载均衡 并桥接注册中心 以Invoker为中心
 拓展接口为Cluster Directory Router LoaderBalance
 6.monitor监控层 RPC调用次数和调用时间监控 以Statistics为中心 拓展接口为MonitorFactory Monitor MonitorService
 现在用的较少  流行：Trace Metrics Elk
 7.protocol层远程调用层 封装RPC调用 以Invocation Result为中心 拓展接口为Protocol Invoker Exporter
 8.exchange信息交换层 封装请求响应模式 同步转异步 以Result Response为中心
 拓展接口 Exchanger ExchangerChannel ExchangeClient ExchangeServer
 9.transport网络传输层 抽象mina和netty为统一接口 Message为中心 拓展接口为
 Channel Transporter Client Server Codec
 10.serialize数据序列化层 拓展接口为Serialization ObjectInput ObjectOutput
 ThreadPool

SPI的应用

ServiceLoader 机制 META-INF/接口全限定名，文件内容为实现类（ShardingSphere使用）

其他两个类似的机制：Callback与EventBus

Dubbo的SPI扩展，最关键的SPI：Protocol xxx=com.alibaba.xxx.XxxProtocol

启动时装配，并缓存到ExtensionLoader中

服务如何暴露
以InjvmProtocol为例， InjvmProtocol InjvmExporter XXInvoker
服务如何引用
ServiceReference 
ReferenceConfig createProxy中创建 Invoker
集群与路由
Cluster
-- Directory : return List<Invoker> 
-- Router ： 选取此次调用可以提供服务的invoker集合 Condition，Script，Tag -- LoadBalance ：从上述集合选取一个作为最终调用者 Random，RoundRobin，ConsistentHash(创造虚拟节点 避免数据倾斜)

泛化引用 GenericService 当我们知道接口、方法和参数，不用存根方式，而是用反射方式调用任何服务

隐式传参 Context模式 
RpcContext.getContext().setAttachment("index", "1"); 此参数可以传播到RPC调用的整个过程。

需要实现一个io.kimmking.HelloServiceMock类可以方便用来做测试

Dubbo应用场景
分布式服务化改造 
业务系统规模复杂，垂直拆分改造 
- 数据相关改造 - 服务设计 
- 不同团队的配合 - 开发、测试运维

平台发展的两个模式：开放模式、容器模式
将公司的业务能力开发出来，形成开发平台，对外输出业务或技术能力。 API与SPI，分布式服务化与集中式ESB

基于Dubbo实现业务中台 将公司的所有业务服务能力，包装成API，形成所谓的业务中台。 前端业务服务，各个业务线，通过调用中台的业务服务，灵活组织自己的业务。 从而实现服务的服用能力，以及对于业务变化的快速响应。

Dubbo最佳实践
开发分包 
建议将服务接口、服务模型、服务异常等均放在 API 包中，因为服务模型和异常也是 API 的一部分，这样做也符合分包原则：重用发布等价原则(REP)，共同重用原则 (CRP)。

服务接口尽可能大粒度，每个服务方法应代表一个功能，而不是某功能的一个步骤，否 则将面临分布式事务问题，Dubbo 暂未提供分布式事务支持

服务接口建议以业务场景为单位划分，并对相近业务做抽象，防止接口数量爆炸

不建议使用过于抽象的通用接口，如：Map query(Map)，这样的接口没有明确语义， 会给后期维护带来不便

环境隔离与分组
怎么做多环境的隔离？ 1、部署多套？ 2、多注册中心机制 3、group机制 4、版本机制

服务接口增加方法，或服务模型增加字段，可向后兼容，删除方法或删除字段，将不兼 容，枚举类型新增字段也不兼容，需通过变更版本号升级。

参数配置
通用参数以 consumer 端为准，如果consumer端没有设置，使用provider数值 
建议在 Provider端配置的 Consumer 端属性有： 
timeout：方法调用的超时时间 
retries：失败重试次数，缺省是 2 
loadbalance：负载均衡算法，缺省是随机 random。 actives：消费者端的最大并发调用限制，即当 Consumer对一个服务的并发调用到上限后，新调用会阻塞直到超时，可以配置在方法或服务上。 建议在 Provider 端配置的 Provider端属性有： 
threads：服务线程池大小 
executes：一个服务提供者并行执行请求上限，即当 Provider 对一个服务的并发调用 达到上限后，新调用会阻塞，此时 Consumer 可能会超时。可以配置在方法或服务上。


容器化部署
注册的IP问题，容器内提供者使用的IP，如果注册到zk，消费者无法访问。 两个解决办法： 
1、docker使用宿主机网络 docker xxx -net xxxxx 2、docker参数指定注册的IP和端口, -e 
DUBBO_IP_TO_REGISTRY — 注册到注册中心的IP地址 
DUBBO_PORT_TO_REGISTRY — 注册到注册中心的端口 
DUBBO_IP_TO_BIND — 监听IP地址 
DUBBO_PORT_TO_BIND — 监听端口

运维与监控
可观测性：tracing、metrics、logging(ELK) 
- APM(skywalking,pinpoint,cat,zipkin,,,) 
- Promethus+Grafana

分布式事务
柔性事务，SAGA、TCC、AT
- Seata 
- hmily + dubbo
不支持 XA

重试与幂等
服务调用失败默认重试2次，如果接口不是幂等的，会造成业务重复处理。 如何设计幂等接口？ 
1、去重-->(bitmap --> 16M), 100w 
2、类似乐观锁机制



分布式服务化

SOA的两个方向：分布式服务化(互联网)和ESB(传统企业)

从RPC走向服务化->微服务架构
具体的分布式业务场景里，除了能够调用远程方法，我们还需要考虑什么？
1、多个相同服务如何管理？ ==> 集群/分组/版本 => 分布式与集群
2、服务的注册发现机制？ ==> 注册中心/注册/发现
3、如何负载均衡，路由等集群功能？ ==> 路由/负载均衡
4、熔断，限流等治理能力。 ==> 过滤/流控
5、心跳，重试等策略。
6、高可用、监控、性能等等。

RPC与分布式服务化的区别
RPC：技术概念
分布式服务化：服务是业务语义，偏向于业务与系统的集成 
proxy service  business service

以分布式服务化框架的角度来看，我们还差前面的这些非功能性需求能力

服务 != 接口，服务可以用接口或接口文档之类的语言描述

分布式服务化与SOA/ESB的区别
SOA/ESB：代理调用，直接增强
服务汇聚到ESB： 
1、暴露和调用
2、增强和中介
3、统计和监控

分布式服务化作为SOA的另一种选择，以不同方式把ESB的一些功能重做了一遍

分布式服务化：直连调用，侧边增强

上面的配置/注册发现等就演化成了代替ESB容器的新组件：配置中心、注册中心等
(非功能性需求)
原本的增强能力去掉了

RPC之上的增强能力根据特点：
1、有状态的部分，放到xx中心
2、无状态的部分，放到应用侧（具体来说是框架和配置部分，尽量不影响业务代码）

状态：需要对数据的最终一致性负责


配置中心 注册中心 元数据中心

配置中心（ConfigCenter）：管理系统需要的配置参数信息
注册中心（RegistryCenter）：管理系统的服务注册、提供发现和协调能力
元数据中心（MetadataCenter）：管理各个节点使用的元数据信息

相同点：都需要保存和读取数据/状态，变更通知
不同点：配置是全局非业务参数，注册中心是运行期临时状态，元数据是业务模型

为什么会需要配置中心？
1、大规模集群下，如何管理配置信息，特别是批量更新问题。
2、大公司和金融行业，一般要求开发、测试、运维分离（物理隔离）。
3、运行期的一些开关控制，总不能不断重启

为什么会需要注册中心？
有什么办法，让消费者能动态知道生产者集群的状态变化？
1、hello.htm -> ok
2、DNS？VIP？ 3、主动报告+心跳
这些信息很重要，后续的集群管控，分布式服务治理，都要靠这个全局状态

为什么会需要元数据中心？
一般情况下，没有问题也不大。有了更好。
元数据中心，定义了所有业务服务的模型。

如何实现XX中心？(见ppt)
最核心的两个要素：
1、需要有存取数据的能力，特别是临时数据的能力。
2、需要有数据变化的实时通知机制，全量或增量。

主流的基座，一般都可以使用namespace的概念，用来在顶层隔离不同环境。
zk没有，但是我们一般用第一个根节点作为namespace。

Zookeeper、etcd、Nacos、Apollo。。。

Model，Center Repository，zk 统一合起来叫配置中心或者注册中心

服务注册
- 服务提供者启动时，将自己注册到注册中心(如zk的实现)的临时节点
- 停止或者宕机时，临时节点消失

注册的数据格式
- 节点key 代表当前服务(或者服务+版本)
- 多个子节点 每一个为一个提供者的描述信息

服务发现
服务消费者启动时，
- 从注册中心代表服务的主节点拿到多个代表提供者的临时节点列表，并在本地缓存
- 根据router和loadbalance算法从其中的某一个执行调用
- 若可用的提供者集合发生变化，注册中心通知消费者刷新本地缓存的列表
如zk使用curator作为客户端操作
curator底层用Guava的cache作缓存
若提供者宕机或者故障，在消费者刷新本地缓存列表时，一部分流量可能会仍然打到这台机器上，这时候就会失效

服务集群
多个服务提供者都提供了同样的服务，这时应该如何处理？
对于完全相同能力的多个服务，我们希望他们能一切协同工作，分摊处理流量。
- 路由
- 负载均衡

服务路由
1、比如基于IP段的过滤
2、再比如服务都带上tag，用tag匹配这次调用范围

服务负载均衡
跟Nginx的负载均衡一样。
多个不同策略，原理不同，目的基本一致（尽量均匀）：
1、Random（带权重）
2、RoundRobin（轮询）
3、LeastActive（快的多给）
4、ConsistentHashLoadBalance（同样参数请求到一个提供者）

服务过滤
所有的复杂处理，都可以抽象为管道+过滤器模式（Channel+Filter）
这个机制是一个超级bug的存在，
可以用来实现额外的增强处理（类似AOP），也可以中断当前处理流程，返回特定数据。
对比考虑一下，我们NIO网关时的filter，servlet的filter等。


服务流控
稳定性工程：
1、我们逐渐意识到一个问题：系统会故障是正常现象，就像人会生病
2、那么在系统出现问题时，直接不服务，还是保持部分服务能力呢？
系统的容量有限。
保持部分服务能力是最佳选择，然后在问题解决后恢复正常状态。
响应式编程里，这就是所谓的回弹性（Resilient）。
需要流控的本质原因是，输入请求大于处理能力。

流控有三个级别：
1、限流（内部线程数，外部调用数或数据量）
2、服务降级（去掉不必要的业务逻辑，只保留核心逻辑）
3、过载保护（系统短时间不提供新的业务处理服务，积压处理完后再恢复输入请求）



微服务


 微服务发展历程：
 单体架构 --> 垂直架构 --> SOA架构 --> 微服务架构

1.响应式微服务
响应式：
即时响应性 可恢复性 弹性 消息驱动
自治性  异步性  伸缩性 回弹性

2.服务网格与云原生
将服务间的网络通信层及其控制策略下沉到基础设施，就形成了所谓的“服务网格”技术
Service Mesh's Control Plane

业务 ---> proxy <---> proxy  Service Mesh统一管理proxy

通过微服务、容器化、持续交付、Devops等技术，组成了所谓的“云原生”体系

3.数据库网格

4.单元化架构
以单元为组织架构，以单元化部署为调度单位
每个单元，是一个五脏俱全的缩小版整站，它是全能的，因为部署了所有应用；但它不是全量的，因为只能操作 一部分数据。能够单元化的系统，很容易在多机房中部署，因为可以轻易地把几个单元部署在一个机房，而把另 外几个部署在其他机房。通过在业务入口处设置一个流量调配器，可以调整业务流量在单元之间的比例。


微服务 --> 服务网格 --> 数据库网格 --> 云原生   
单元化架构：传统行业

微服务架构应用场景
复杂度低的情况下，微服务应用生产力比单体架构低
复杂度高的情况下，情况相反
随着复杂度上升，单体架构生产力迅速下降，微服务相对平稳

如何应用微服务架构
调研 分析 规划 组织  ---  准备阶段
拆分 部署 治理 改进  ---  实施阶段

微服务架构最佳实践
1.遗留系统改造
①功能剥离、数据解耦 ②自然演进、逐步拆分 ③小步快跑、快速迭代 ④灰度发布、谨慎试错 ⑤提质量线、还技术债
2.恰当粒度拆分
拆分原则：1.高内聚低耦合  2.不同阶段拆分要点不同  具体问题具体分析
3.拓展立方体
单元化架构的基础
1.水平复制：复制系统 2.功能解耦：拆分业务 3.数据分区：切分数据 
4.自动化管理
自动化测试 自动化部署 自动化运维
降低服务拆分带来的复杂性 提升测试 部署 运维效率
5.分布式事务
幂等 去重 补偿  慎用分布式事务！
6.完善监控体系
1.业务监控 2.系统监控 3.容量规划 4.报警预警 5.运维流程 6.故障处理
稳定性建设

Spring Cloud技术体系
见ppt
- Config/Eureka/Consul
- Zuul/Zuul2/Spring Cloud Gateway
- Feign/Ribbon
- Hystrix/Alibaba Sentinel

微服务相关框架与工具
相关工具-APM
APM：应用性能监控 - Apache Skywalking - Pinpoint - Zipkin - Jaeger 
监控- ELK - promethus+Grafana - MQ+时序数据库 (InfluxDB/openTSDB等)
可观测性：
- Logging
- Tracing
- Metrics

相关工具-权限控制
最核心的3A（其他：资源管理、安全加密等）： 
- Authc: Authentication 
- Authz: Authorization 
- Audit
CAS+SSO(TGT、ST) JWT/Token, OAuth2.0 SpringSecurity, Apache Shiro

相关工具-数据处理
1、读写分离与高可用HA： 2、分库分表Sharding： 3、分布式事务DTX： 4、数据迁移Migration： 5、数据集群扩容Scaling： 6、数据操作审计Audit：

相关工具-网关与通信
1、流量网关与WAF(Nginx/OR/Kong/Apisix) 
2、业务网关(Zuul/Zuul2/SCG) 
3、REST与其他协议之争（websocket/actor/rsocket/mq...）

缓存

1.数据分类
- 静态数据：一般不变 类似字典表
- 准静态数据：变化频率低 部门结构设置 全国行政区划数据等
- 中间状态数据： 一些计算的可复用中间数据 变量副本 配置中心的本地副本  

- 热数据：使用频率高
- 读写比较大： 读的频率 >> 写的频率

允许丢失
离cpu越近，离I/O越远

这些数据适合使用缓存的方式访问

内存 ~ 可以看做是 CPU 和 磁盘之间的缓存 
CPU与内存的处理速度也不一致，出现 L1&L2 Cache 
网络处理，数据库引擎的各种Buffer，都可以看做是缓存 
GUI的Double Buffer（双缓冲），是一个经典的性能优化方法

缓存的本质：系统的各级处理速度不匹配，导致利用空间换时间
缓存是提升系统性能的一个简单有效方法

缓存加载时机

1.启动全量加载 --> 全局有效，使用简单

2.懒加载
同步使用加载 --> 
- 先看缓存是否有数据，没有的话从数据库读取 - 读取的数据，先放到内存，然后返回给调用方
延迟异步加载 -->
- 从缓存获取数据，不管是否为空直接返回 -->
- 策略1异步）如果为空，则发起一个异步加载的线程，负责加载数据 
- 策略2解耦）异步线程负责维护缓存的数据，定期或根据条件触发更新

允许数据不一致

变动频率大 一致性要求高的数据 不适合做缓存
变化大，意味着内存缓存数据<-->原始数据库数据，一直有差异
一致性要求高 意味着只有使用原始数据，甚至加了事务才是保险的

缓存有效性
读写比：N：1  一般要求10：1以上
命中率：命中缓存意味着缓存数据被使用，是有价值的 90%+

一般系统读写比都比较高  高频交易系统，读写比很低，甚至1：10，1：100

数据一致性，性能，成本综合衡量，是引入缓存的必须指标

缓存使用不当导致的问题
1.系统预热导致启动慢
系统不能做到快速应对故障宕机等问题
2.系统内存资源耗尽
数据清理不及时，只加入数据，不能清除旧数据

本地缓存
1.最简单的本地缓存：new HashMap()
2.Hibernate/MyBatis都有Cache
一级缓存，session级别。 二级缓存，sessionFactory级别。
3.Guava Cache



Spring Cache
1、基于注解和AOP，使用非常方便 
2、可以配置Condition和SPEL，非常灵活 
3、需要注意：绕过Spring的话，注解无效

核心功能：@Cacheable、@CachePut、@CacheEvict
参考：https://developer.ibm.com/zh/articles/os-cn-spring-cache/

可以配置在service上，也可以配置在dao上(类似mybatis的缓存)


本地缓存的缺点：
1.集群规模增大，缓存的读写放大
2.JVM长期占用内存，若是堆内存，总是会影响GC
3.缓存数据的调度处理，影响执行业务的线程，抢占资源

===> 集中处理缓存

缺点：
1.所有的数据请求多了中间网络的这一跳
2.类似redis，某个业务节点访问redis，导致缓存的资源利用率较高，操作较慢，则会导致缓存服务器给其他的业务提供能力下降

远程缓存
REmote DIctionary Server(Redis)
Redis 官网：https://redis.io/ 
Redis 在线测试：http://try.redis.io/ 
Redis 命令参考：http://doc.redisfans.com/ 
《Redis 设计与实现》：http://redisbook.com/ 
Memcached 官网：https://memcached.org/

Hazelcast/Ignite 内存网格

缓存策略
容量：
资源有限
-缓存数据容量是必须要考虑的问题
-思考系统的设计容量 使用容量 峰值是我们做架构设计的常识   
过期策略：
- 按FIFO或者LRU
- 按固定时间过期
- 按业务时间加权：例如3+5X 航空公司机票

缓存常见问题
缓存穿透：
大量并发查询不存在的KEY，导致都直接将压力透传到数据库
为什么会多次透传呢？
不存在，一直为空。 
需要注意让缓存能够区分KEY不存在和查询到一个空值。

解决办法： 
1、缓存空值的KEY，这样第一次不存在也会被加载会记录，下次拿到有这个KEY。 2、Bloom过滤或RoaringBitmap 判断KEY是否存在。 
3、完全以缓存为准，使用延迟异步加载的策略2，这样就不会触发更新。

缓存击穿：
问题：某个KEY失效的时候，正好有大量并发请求访问这个KEY。 分析：跟前面一个其实很像，属于比较偶然的。

解决办法： 
1、KEY的更新操作添加全局互斥锁。 
2、完全以缓存为准，使用延迟异步加载的策略2，这样就不会触发更新。


缓存雪崩：
问题：当某一时刻发生大规模的缓存失效的情况，会有大量的请求进来直接打到数据库，导致数 据库压力过大升值宕机。

分析：一般来说，由于更新策略、或者数据热点、缓存服务宕机等原因，可能会导致缓存数据同 一个时间点大规模不可用，或者都更新。所以，需要我们的更新策略要在时间上合适，数据要均 匀分散，缓存服务器要多台高可用。

解决办法： 
1、更新策略在时间上做到比较均匀。 
2、使用的热数据尽量分散到不同的机器上。 
3、多台机器做主从复制或者多副本，实现高可用。 
4、实现熔断限流机制，对系统进行负载能力控制。



redis详解

redis安装
redis性能测试
自带命令：redis-benchmark
# redis-benchmark -n 100000 -c 32 -t SET,GET,INCR,HSET,LPUSH,MSET -q

Redis的5种基本数据结构
1.字符串 ~ int string byte[]
最基础的数据存储类型
常用命令
set/get/getset/del/exists/append 
incr/decr/incrby/decrby
注意： 
1、字符串append：会使用更多的内存 2、整数共享：如果能使用整数，就尽量使用整数，限制了redis内存+LRU 3、整数精度问题：redis大概能保证16~，，17-18位的大整数就会丢失精确

2.散列 - Map ~ Pojo Class
Redis中的Hash类型可以看成具有String key 和String value的map容器
适合存储对象的信息
常用命令
hset/hget/hmset/hmget/hgetall/hdel/hincrby 
hexists/hlen/hkeys/hvals

3.列表（list）~ java的LinkedList
在Redis中，List类型是按照插入顺序排序的字符串链表。和数据结构中的普通链表 一 样，我们可以在其头部(Left)和尾部(Right)添加新的元素
常用命令
lpush/rpush/lrange/lpop/rpop

4.集合（set）~ java的set，不重复的list
在redis中，可以将Set类型看作是没有排序的字符集合，和List类型一样，我们也可以 在该类型的数值上执行添加、删除和判断某一元素是否存在等操作。这些操作的时间复 杂度为O(1),即常量时间内完成依次操作。 和List类型不同的是，Set集合中不允许出现重复的元素。
常用命令
sadd/srem/smembers/sismember ~ set.add, remove, contains
sdiff/sinter/sunion ~ 集合求差集，求交集，求并集

5.有序集合（sorted set）
sortedset和set极为相似，他们都是字符串的集合
都不允许重复的成员出现在一个set中。
他们之间的主要差别是sortedset中每一个成员都会有一个分数与之关联。
redis正是通过分数来为集合的成员进行从小到大的排序。sortedset中分数是可以重复的。
常用命令
zadd key score member score2 member2... : 将成员以及该成员的分数存放到sortedset中 zscore key member : 返回指定成员的分数 
zcard key : 获取集合中成员数量 zrem key member [member...] : 移除集合中指定的成员，可以指定多个成员

Redis的3种高级数据结构
- Bitmaps：setbit/getbit/bitop/bitcount/bitpos
- Hyperloglogs：pfadd/pfcount/pfmerge
- GEO：geoadd/geohash/geopos/geodist/georadius/georadiusbymember

Redis 到底是单线程，还是多线程？
IO线程： - redis 6之前（2020年5月），单线程 
- redis 6之后，多线程，NIO模型 ==> 主要的性能提升点 
内存处理线程： - 单线程 ==> 高性能的核心

Redis六大使用场景

1.业务数据缓存
1、通用数据缓存，string，int，list，map等。 
2、实时热数据，最新500条数据。 
3、会话缓存，token缓存等。

2.业务数据处理
1、非严格一致性要求的数据：评论，点击等。 
2、业务数据去重：订单处理的幂等校验等。 
3、业务数据排序：排名，排行榜等。

3.全局一致计数 
1、全局流控计数 2、秒杀的库存计算 3、抢红包 4、全局ID生成

4.高效统计计数
1、id去重，记录访问ip等全局bitmap操作 
2、UV、PV等访问量==>非严格一致性要求

5.发布订阅与Stream
1、Pub-Sub 模拟队列 subscribe comments publish comments java
2、Redis Stream 是 Redis 5.0 版本新增加的数据结构。 Redis Stream 主要用于消息队列（MQ，Message Queue）
https://www.runoob.com/redis/redis-stream.html

6.分布式锁 
1、获取锁--单个原子性操作 SET dlock my_random_value NX PX 30000 
2、释放锁--lua脚本-保证原子性+单线程，从而具有事务性 
if redis.call("get",KEYS[1]) == ARGV[1] then 
    return redis.call("del",KEYS[1]) 
else
    return 0 
end 

关键点：原子性、互斥、超时

先到redisget锁 + del锁这样行不行？
极端情况下不行
需要把他们放到一起，让redis把他们作为原子来操作
使用lua脚本
执行脚本时，redis的内存模型单线程能保证原子性

lua脚本运行时，redis不会对外提供任何服务
对于线上redis，吞吐量较大，不要使用复杂的lua脚本，不要使用范围查询操作，如keys *等，非常耗时

Redis的Java客户端
1.Jedis
官方客户端，类似JDBC，可看作是对redis命令的包装
基于BIO，线程不安全，需要配置连接池管理连接

2.Lettuce
目前主流推荐的驱动，基于Netty NIO，API线程安全

3.Redission
基于Netty NIO，API线程安全。 
亮点：大量丰富的分布式功能特性，比如JUC的线程安全集合和工具的分布式版本，分布式的基本数据类型和锁等。

Redis与Spring整合
Spring Data Redis 核心是 RedisTemplate(可以配置基于Jedis，Lettuce，Redisson) 使用方式类似于MongoDBTemplate，JDBCTemplate或JPA 封装了基本redis命令操作

Spring Boot与Redis集成
引入 spring-boot-starter-data-redis 
配置 spring redis

Spring Cache与Redis集成
默认使用全局的CacheManager自动集成 使用ConcurrentHashMap或ehcache时，不需要考虑序列化问题。 redis的话，需要： 1、默认使用java的对象序列化，对象需要实现Serializable 2、自定义配置，可以修改为其他序列化方式


HA = (总时间-不可用时间)/总时间

两个系统，一个月30天，A系统每天宕机一次，一次1分钟，B系统一个月宕机一次，一次宕机30分钟，哪个系统好？
从可用性角度来看，是一样的，从稳定性角度来看，B系统较好。


Redis高级功能

Redis事务
开启事务 multi
命令入队
执行事务 exec
撤销事务 discard

- Watch 实现乐观锁

watch一个key 发送变化则事务失败

Redis Lua
- 类似于数据库的存储过程，mongodb的js脚本 
直接执行 eval "return'hello java'" 0 eval "redis.call('set',KEYS[1],ARGV[1])" 1 lua-key lua-value 
预编译 script load script脚本片段 返回一个SHA-1签名 shastring 
evalsha shastring keynum [key1 key2 key3 ...] [param1 param2 param3 ...]


Redis管道技术
合并操作批量处理 且不阻塞前序命令
% (echo -en "PING\r\n SET pkey redis\r\nGET pkey\r\nINCR visitor\r\nINCR visitor\r\nINCR visitor\r\n"; sleep 1) | nc localhost 6379


Redis数据备份和恢复
RDB
备份：
执行save即可在redis数据目录生成数据文件 dump.rdb
异步执行 bgsave

恢复
备份文件(dump.rdb)移动到redis数据目录并启动服务
查看文件夹 
CONFIG GET dir 127.0.0.1:6379> CONFIG GET dir 
1) "dir" 
2) "/data"


AOF~binlog
备份
如果 appendonly 配置为 yes，则以 AOF 方式备份 Redis 数据，那么此时 Redis 会按 照配置，在特定的时候执行追加命令，用以备份数据。
appendfilename "appendonly.aof" 
# appendfsync always 
# appendfsync everysec 
# appendfsync no......

AOF 文件和 Redis 命令是同步频率的，假设配置为 always，其含义为当 Redis 执行 命令的时候，则同时同步到 AOF 文件，这样会使得 Redis 同步刷新 AOF 文件，造成 缓慢。而采用 evarysec 则代表每秒同步一次命令到 AOF 文件。

恢复
自动加载

Redis 性能优化
- 核心优化点： 
1、内存优化~ 10G/20G 
https://redis.io/topics/memory-optimization 
hash-max-ziplist-value 64 
zset-max-ziplist-value 64 
2、CPU优化 
不要阻塞 
谨慎使用范围操作 
SLOWLOG get 10 默认10毫秒，默认只保留最后的128条

Redis 使用的一些经验 
1、性能： 1) 线程数(4~8)与连接数(redis~10000)； 
2) 监控系统读写比和缓存命中率(N:1,90%+)； 
2、容量： 1) 做好容量评估，合理使用缓存资源； 
3、资源管理和分配： 
1) 尽量每个业务集群单独使用自己的Redis，不混用； 
2) 控制Redis资源的申请与使用，规范环境和Key的管理（以一线互联网为例）； 
3) 监控CPU100%，优化高延迟的操作。

消息队列基础

系统间的通信方式
基于文件  基于共享内存  基于IPC  基于Socket  基于数据库 基于RPC

各个模式的缺点：
- 文件：明显不方便 不及时
- Socket：使用麻烦 多数情况下不如RPC
- 数据库：不实时 但是经常有人拿数据库来模拟消息队列(A系统不停往数据库写，另一个系统不停轮询取数)
- RPC：调用关系复杂，同步处理，压力大的时候无法缓冲

 MQ(Message Queue)
 可以类比快递服务

 从队列到消息服务
 - 内存里的Queue
 可用单链表或者数组(ring buffer 回环队列)实现

 -Message Queue 
 消息：1.流动 2.具有业务意义

 MQ四大作用
 - 异步通信：异步通信，减少线程等待，特别是处理批量等大事务，耗时操作
 - 系统解耦：系统不直接调用，降低依赖
 - 削峰填谷：压力大的时候，缓冲部分请求消息
 - 可靠通信：提供多种消息模式，服务质量，顺序保障等

 消息模式与消息协议
 消息处理模式：
 1.PTP 点对点  对应于Queue
 2.发布订阅 PubSub 对应于Topic

 消息处理的保障
 消息语义，并非业务语义
 - At most once 至多一次 消息可能丢失，但不会重复发送
 - At least once 至少一次 消息不会丢失 但可能会重复 (可在业务侧进行幂等去重处理)
 - Exactly once 精确一次 每条消息肯定被传输一次且仅一次

 消息处理的事务性
 - 通过确认机制实现事务性
 - 被事务管理器管理，可以支持XA

消息有序性
同一个Topic或者Queue的消息 保障按顺序投递
若做了消息分区或者批量预取的操作，不能保证顺序


消息协议
STOMP 
JMS* (客户端接口层API)
AMQP* MQTT* (四层协议都有)
XMPP Open Messaging

客户端和MQ之间有四层协议：1.网络层 2.数据传输的形式 3.客户端接口的API 4.交互的协议

JMS
关注于应用层的API协议( ~ 类似JDBC)
Message结构与Queue概念 
• Body\Header\Property, messages types 
• Queue\Topic\TemporaryQueue\TemporaryTopic 
• Connection\Session\Producer\Consumer\DurableSubscription

Messaging行为 
• PTP&Pub-Sub 
• 持久化 
• 事务机制 
• 确认机制 
• 临时队列


消息队列的通用结构
客户端应用层：发送和接收消息的API接口 
消息模型层：消息、连接、会话、事务等等 
消息处理层：消息交互逻辑定义、持久化 
网络传输层：序列化协议、传输协议、可靠机制

开源消息中间件/消息队列
三代： 
1、ActiveMQ/RabbitMQ 
2、Kafka/RocketMQ 
3、Apache Pulsar

ActiveMQ消息中间件
高可靠的、事务性的消息队列 
当前应用最广泛的开源消息中间件 
项目开始与2005年CodeHaus、2006年成为Apache项目


功能最全的开源消息队列 支持各种协议
https://activemq.apache.org/
主要功能 
1. 多种语言和协议编写客户端。 语言: Java, C, C++, C#, Ruby, Perl, Python, PHP等应用协议: OpenWire,Stomp REST,WS Notification,XMPP,AMQP,MQTT 
2. 完全支持JMS1.1和J2EE 1.4规范 (持久化,XA消息,事务) 
3. 与Spring很好地集成，也支持常见J2EE服务器 
4. 支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA 
5. 支持通过JDBC和journal提供高速的消息持久化 
6. 实现了高性能的集群模式

使用场景
1、所有需要使用消息队列的地方； 
2、订单处理、消息通知、服务降级等等； 
3、特别地，纯Java实现，支持嵌入到应用系统。

kafka

概念：
kafaka是一个分布式,基于发布/订阅的消息系统
1.以时间复杂度为O(1)的方式提供消息持久化能力 
2.高吞吐率 
3.支持kafka Server间的消息分区及分布式消费 同时保证每个Partition内的消息顺序传输
4.支持离线数据处理和实时数据处理
5.Scale out 支持在线水平拓展

基本概念
1.Broker：kafka集群包含一个或多个服务器 这种服务器被称为broker
2.Topic：每条发布到kafka集群的消息都有一个类别，这个类别被称为Topic
（物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或 多个 broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数 据存于何处）
3.Partition 物理概念 每个Topic包含一个或者多个Partition
4. Producer：负责发布消息到 Kafka broker。 
5. Consumer：消息消费者，向 Kafka broker 读取消息的客户端。 
6. Consumer Group：每个 Consumer 属于一个特定的 Consumer Group（可为每个 Consumer 指定 group name，若不指定 group name 则属于默认的 group）。 (类似实现PTP模式)

kafka单机消息处理 record
kafka集群消息处理 集群信息存在zk上

多Partition支持水平拓展和并行处理，顺序写入提升吞吐性能
每个Partition可以通过副本因子添加多个副本
例如4节点，3副本，2确认   5节点，4副本，3确认

Topic特性
1.通过Partition(Queue)增加可拓展性
2.通过顺序写入达到高吞吐
3.多副本增加容错性

集群与多副本的说明
1、ISR：In-Sync Replica 
2、Rebalance：broker和consumer group的rebalance 3、热点分区：需要重新平衡


Kafka的高级特性
生产者-执行步骤  客户端实现序列化，分区，压缩操作
生产者-确认模式
ack=0 : 只发送不管有没有写入到broker 
ack=1：写入到leader就认为成功 
ack=-1/all：写入到最小的复本数则认为成功

生产者特性-同步发送
生产者特性-异步发送
生产者特性-顺序保证
生产者特性-消息可靠性传递

消费者-Consumer Group
1.4个Partition consumer group中有2个consumer；则1个consumer消费2个partition
2.consumer group中有3个consumer，则1个consumer消费2个partition，其余2个consumer各自消费1个partition
3.consumer group中有4个consumer，则每个consumer各自消费1个partition
4.consumer group中有5个consumer，则4个consumer各自消费1个partition，另一个闲置

消费者特性-Offset同步提交
消费者特性-Offset异步提交
消费者特性-Offset自动提交
消费者特性-Offset Seek(提交offest到db)

offset记录消费的位置









